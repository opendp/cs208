{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Sample-and-Aggregate algorithm using our DP Mean and Gaussian Mechanism\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "78f3ba1e-c430-4839-849d-51c0e75137e3",
        "deepnote_cell_type": "markdown",
        "id": "vSPQDq18BMDZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "753f31f1",
        "execution_start": 1645071266172,
        "execution_millis": 12929863,
        "deepnote_output_heights": [
          79
        ],
        "cell_id": "00001-8278110f-f149-40fc-b716-e5f4751207c8",
        "deepnote_cell_type": "code",
        "id": "cYhLhN4vBMDa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# established in previous lectures\n",
        "#from mock_dp_library import *"
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# introduced in wk3\n",
        "# functions used regularly in examples\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def laplace(shift=0., scale=1., size=None):\n",
        "    \"\"\"Sample from the laplace distribution.\"\"\"\n",
        "    p = np.random.uniform(low=-0.5, high=0.5, size=size)\n",
        "    draws = shift - scale * np.sign(p) * np.log(1 - 2 * abs(p))\n",
        "    return draws\n",
        "\n",
        "    # the easy way\n",
        "    # return np.random.laplace(loc=shift, scale=scale, size=size)\n",
        "\n",
        "\n",
        "def gaussian(shift=0., scale=1., size=None):\n",
        "    \"\"\"Sample from the Gaussian distribution.\"\"\"\n",
        "    draws = np.random.normal(loc=shift, scale=scale, size=size)\n",
        "    return draws\n",
        "\n",
        "\n",
        "def clamp(x, bounds):\n",
        "    \"\"\"Replace any x_i less than lower with lower,\n",
        "           and any x_i greater than upper with upper.\"\"\"\n",
        "    return np.clip(x, *bounds)\n",
        "\n",
        "\n",
        "def bounded_mean(x, bounds):\n",
        "    x_clamped = clamp(x, bounds)\n",
        "    return np.mean(x_clamped)\n",
        "\n",
        "\n",
        "def release_dp_mean(x, bounds, epsilon, delta=1e-6, mechanism=\"laplace\"):\n",
        "    \"\"\"Release a DP mean.\n",
        "    Assumes that the dataset size n is public information.\n",
        "    \"\"\"\n",
        "    sensitive_mean = bounded_mean(x, bounds)\n",
        "\n",
        "    n = len(x)\n",
        "    lower, upper = bounds\n",
        "    # Sensitivity in terms of an absolute distance metric\n",
        "    # Both the laplace and gaussian mechanisms can noise queries\n",
        "    #    with sensitivities expressed in absolute distances\n",
        "    sensitivity = (upper - lower) / n\n",
        "\n",
        "    if mechanism == \"laplace\":\n",
        "        scale = sensitivity / epsilon\n",
        "        dp_mean = sensitive_mean + laplace(scale=scale)\n",
        "    elif mechanism == \"gaussian\":\n",
        "        scale = (sensitivity / epsilon) * np.sqrt(2*np.log(2/delta))\n",
        "        dp_mean = sensitive_mean + gaussian(scale=scale)\n",
        "    else:\n",
        "        raise ValueError(f\"unrecognized mechanism: {mechanism}\")\n",
        "\n",
        "    return dp_mean\n",
        "\n",
        "\n",
        "def bootstrap(x, n):\n",
        "    \"\"\"Sample n values with replacement from n.\"\"\"\n",
        "    index = np.random.randint(low=0., high=len(x), size=n)\n",
        "    return x[index]\n",
        "\n",
        "\n",
        "def release_dp_histogram(x, epsilon, categories):\n",
        "    \"\"\"Release an `epsilon`-DP estimate of the counts of each of the `categories`\"\"\"\n",
        "    sensitivity = 2\n",
        "    scale = sensitivity / epsilon\n",
        "\n",
        "    # create a {category: count} hashmap\n",
        "    counts = dict(zip(*np.unique(x, return_counts=True)))\n",
        "    # look up the count of each category, or zero if not exists\n",
        "    sensitive_histogram = np.array([counts.get(cat, 0) for cat in categories])\n",
        "\n",
        "    dp_histogram = sensitive_histogram + laplace(scale=scale, size=sensitive_histogram.shape)\n",
        "    return dp_histogram"
      ],
      "metadata": {
        "id": "i1G02HnwBPXw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in the data.  We're going to use the PUMS dataset we are familiar with, and focus on the education variable, a 16 point scale."
      ],
      "metadata": {
        "tags": [],
        "is_collapsed": false,
        "cell_id": "00002-e081a640-a554-4c7d-a764-c9b90faaf7e1",
        "deepnote_cell_type": "text-cell-p",
        "id": "mYxl9aCxBMDa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "af79b62e",
        "execution_start": 1645071266174,
        "execution_millis": 179,
        "cell_id": "00003-f98ddaaa-2be5-47bf-96fc-7236782cb280",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keh0f2h_BMDa",
        "outputId": "b1cb0645-1cd6-4439-a9e2-2eff682c5a1d"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/opendp/cs208/main/spring2022/data/FultonPUMS5full.csv\")\n",
        "\n",
        "# define public information\n",
        "n = len(data)            # in this case, dataset length is considered public, and is not protected\n",
        "educ_bounds = (1., 16.)  # easily guessable without looking at the data\n",
        "\n",
        "educ = data['educ'].values.astype(float)\n",
        "print(release_dp_mean(educ, bounds=educ_bounds, epsilon=1.))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.608234813359998\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "83a41178-8e38-4063-9698-2ec152692fe4",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6faa249a",
        "execution_start": 1645071266424,
        "execution_millis": 11548385,
        "deepnote_cell_type": "code",
        "id": "HFdyGfSnBMDb"
      },
      "source": [
        "def sample_aggregate(data: pd.DataFrame, function, partition_count: int, bounds, epsilon, delta):\n",
        "\n",
        "    ## SAMPLE\n",
        "    # shuffle without replacement\n",
        "    data = data.sample(frac=1, replace=False)\n",
        "    # split data into `partition_count` datasets\n",
        "    partitions = np.array_split(data, partition_count)\n",
        "\n",
        "    ## EVALUATE\n",
        "    results = []\n",
        "    for partition in partitions:\n",
        "        results.append(function(partition))\n",
        "\n",
        "    ## AGGREGATE\n",
        "    private_release = release_dp_mean(\n",
        "        results, bounds=bounds, epsilon=epsilon, delta=delta, mechanism=\"gaussian\")\n",
        "\n",
        "    return(private_release)"
      ],
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "ae58b3eb-57ac-4ed0-b43b-1668a9eeb4a1",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "8cff4794",
        "execution_start": 1645071453290,
        "execution_millis": 333,
        "deepnote_output_heights": [
          21,
          367
        ],
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nc9J3hIBMDb",
        "outputId": "f985191b-a4f1-401a-8756-d9cb4151a546"
      },
      "source": [
        "def correlation(data):\n",
        "    return np.corrcoef(data['educ'], data['income'])[0, 1]\n",
        "\n",
        "\n",
        "dp_correlation = sample_aggregate(\n",
        "    data, correlation, partition_count=200, bounds=[0,1], epsilon=1, delta=1e-6)\n",
        "\n",
        "print(\"True correlation:\", correlation(data))\n",
        "print(\"DP   correlation:\", dp_correlation)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True correlation: 0.35472882626591723\n",
            "DP   correlation: 0.34310199984026224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "f2025fad-a47b-4376-94c6-10ee7c164b69",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b623e53d",
        "execution_start": 1645071268251,
        "deepnote_cell_type": "code",
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oyBLorEvBMDb"
      },
      "source": [],
      "outputs": [],
      "execution_count": 6
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_notebook_id": "dfde62b0-d99f-4ff8-9850-1a15067c4a22",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}